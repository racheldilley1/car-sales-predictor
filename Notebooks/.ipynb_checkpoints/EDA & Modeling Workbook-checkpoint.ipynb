{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder, normalize\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/model_spec_sales_df.pkl')\n",
    "#df.drop(labels=['width_in','doors', 'length_in', 'height_in', 'volume_cuft'], axis=1, inplace=True)\n",
    "df1 = df.loc[:,['price', 'doors', 'passengers', 'speed_sec', 'horsepower_hp', 'drive', 'mpg', 'engine', 'tank_gal',\n",
    "                'length_in', 'width_in','height_in', 'Total_Sales']]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df1.corr(), cmap=\"seismic\", annot=True, vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check categorical features to see if it is related to Total Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(x=df1['drive'], y=df1['Total_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df1['engine'], y=df1['Total_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df1['doors'], y=df1['Total_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df1['passengers'], y=df1['Total_Sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intial Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What is the distribution of the target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Are there any colinearities in the feartures?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find neg/positive colinearities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What are the relationships between each features and the targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far there does not appear to be any obvious linear relationships between features and the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_value(X_test,y_test, model):\n",
    "    \n",
    "    #ensure x_test has same columns as train data\n",
    "    #X_test = X_test.reindex(columns = val_cols)\n",
    "    #X_test.fillna(0, inplace=True)\n",
    "    \n",
    "    #test_set_pred = lasso_model.predict(X_test.loc[:,selected_columns])\n",
    "    test_set_pred = model.predict(X_test)\n",
    "    \n",
    "    #plot \n",
    "#     plt.scatter(test_set_pred, y_test, alpha=.1)\n",
    "#     plt.plot(np.linspace(0,600000,1000), np.linspace(0,600000,1000))\n",
    "    \n",
    "    #mae\n",
    "    print(f\"The Mean Absolute Error is {np.mean(np.abs(y_test - test_set_pred))}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define features(X) and Target(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = df1[['drive', 'engine', 'doors', 'passengers']]\n",
    "X_num = df1[['price', 'speed_sec', 'horsepower_hp', 'mpg', 'tank_gal', 'length_in', 'width_in', 'height_in']]\n",
    "X = df1[['price', 'speed_sec', 'horsepower_hp', 'mpg', 'tank_gal', 'length_in', 'width_in', 'height_in', \n",
    "         'drive', 'engine', 'doors', 'passengers']]\n",
    "y = df1['Total_Sales']\n",
    "\n",
    "# create overall quality squared term, which we expect to \n",
    "# help based on the relationship we see in the pair plot \n",
    "# X['OQ2'] = X['Overall Qual'] ** 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = sm.OLS(y,X_num)\n",
    "baseline_fit = baseline_model.fit()\n",
    "baseline_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data into train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold out 20% of the data for final testing\n",
    "#change random state for new subset\n",
    "X = pd.get_dummies(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=46)\n",
    "# X_test.shape\n",
    "# y_test.shape\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regular Validation for Linear and Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_regression(X,y):\n",
    "    \n",
    "    #split so validation data is 20% of original data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=14)\n",
    "    \n",
    "    #ensure x_val has same columns as train data\n",
    "#     val_cols = X_train.columns\n",
    "#     X_val = X_val.reindex(columns = val_cols)\n",
    "#     X_val.fillna(0, inplace=True)\n",
    "    \n",
    "    #Feature scaling for train, val, and test\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "#     X_val_scaled = scaler.transform(X_val.values)\n",
    "    \n",
    "    # fit linear regression to training data\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # score fit model on validation data\n",
    "    val_score = lr_model.score(X_val, y_val)\n",
    "    \n",
    "    # report results\n",
    "    print('\\nValidation R^2 score was:', val_score)\n",
    "    print('Feature coefficient results: \\n')\n",
    "    for feature, coef in zip(X_train.columns, lr_model.coef_):\n",
    "        print(feature, ':', f'{coef:.2f}') \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression(X,y, degree, interaction):\n",
    "    \n",
    "    #split so validation data is 20% of original data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=20)\n",
    "    \n",
    "    #ensure x_val has same columns as train data\n",
    "#     val_cols = X_train.columns\n",
    "#     X_val = X_val.reindex(columns = val_cols)\n",
    "#     X_val.fillna(0, inplace=True)\n",
    "    \n",
    "    #create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, interaction_only = interaction)\n",
    "    X_train_poly = poly.fit_transform(X_train.values)\n",
    "    X_val_poly = poly.transform(X_val.values)\n",
    "    \n",
    "    # fit poly features to linear regression to training data\n",
    "    lm_poly = LinearRegression()\n",
    "    lm_poly.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # score fit model on validation data and report results\n",
    "    print(f'\\nDegree {degree}, interaction_only = {interaction} polynomial regression R^2 val: \n",
    "          {lm_poly.score(X_val_poly, y_val):.3f}')\n",
    "    print('Feature coefficient results: \\n')\n",
    "    for feature, coef in zip(poly.get_feature_names(), lm_poly.coef_):\n",
    "        print( f'Coef of {feature} is : {coef:.2f}')\n",
    "#     for feature, coef in zip(X_train.columns, lm_poly.coef_):\n",
    "#         print(feature, ':', f'{coef:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_linear_regression(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_regression(X_train,y_train,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Severely negative R^2 score for polynomial regression tells us that the model is overfit and that evidence points towards a simple linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_lasso_reg(folds, alpha_start, alpha_end, alpha_step, X_train, y_train, X_test, y_test):  \n",
    "    #create polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "    X_train_poly = poly.fit_transform(X_train.values)\n",
    "    X_test_poly = poly.transform(X_test.values)\n",
    "    #x_train_poly = p.fit_transform(X_train)\n",
    "    #poly.fit(x_train_poly,y_train)\n",
    "    #m.score(x_train_poly,y_train)\n",
    "    std = StandardScaler(with_mean=False)\n",
    "    X_train_poly_scaled = std.fit_transform(X_train_poly.values)\n",
    "    X_test_poly_scaled = std.transform(X_test_poly.values)\n",
    "    \n",
    "    cv = RepeatedKFold(n_splits=folds, n_repeats=3, random_state=1)\n",
    "    # define model\n",
    "    model = LassoCV(alphas=arange(alpha_start, alpha_end, alpha_step), cv=cv)\n",
    "    # fit model\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    #X_te = normalize(X_test,axis=0,return_norm=False)\n",
    "    mae_value(X_test_poly_scaled, y_test,  model)\n",
    "    print(model.score(X_test_poly_scaled, y_test))\n",
    "    #r2_value(X_te, y_test, lr_model_ridge)\n",
    "    print('Feature coefficient results: \\n')\n",
    "    for feature, coef in zip(poly.get_feature_names(), model.coef_):\n",
    "        print(feature, ':', f'{coef:.2f}')        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this helps with the way kf will generate indices below\n",
    "X, y = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_cv(X,y,regularization):\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 71) #randomly shuffle before splitting\n",
    "    cv_lm_r2s = [] #collect the validation results\n",
    "    \n",
    "    #returns 5 index sets for cross vallidation\n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        #ensure x_val has same columns as train data\n",
    "#         val_cols = X_train.columns\n",
    "#         X_val = X_val.reindex(columns = val_cols)\n",
    "#         X_val.fillna(0, inplace=True)\n",
    "    \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        #simple linear regression\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(X_train, y_train)\n",
    "        cv_lm_r2s.append(round(lm.score(X_val, y_val), 3)) \n",
    "        \n",
    "    #report results\n",
    "    print('Simple regression scores: ', cv_lm_r2s, '\\n')\n",
    "    print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_cv(X,y,False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_value( X_test,y_test, cols, model):\n",
    "    \n",
    "    #ensure x_test has same columns as train data\n",
    "    #X_test = X_test.reindex(columns = cols)\n",
    "    #X_test.fillna(0, inplace=True)\n",
    "    \n",
    "    #test_set_pred = lasso_model.predict(X_test.loc[:,selected_columns])\n",
    "    test_set_pred = model.predict(X_test)\n",
    "    \n",
    "    #plot \n",
    "#     plt.scatter(test_set_pred, y_test, alpha=.1)\n",
    "#     plt.plot(np.linspace(0,600000,1000), np.linspace(0,600000,1000))\n",
    "    \n",
    "    #r2 score\n",
    "    print(f\"The r^2 score is {r2_score(y_test, test_set_pred)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_model_cv(X_train, y_train, a, X_test, y_test):\n",
    "    '''\n",
    "    build ridge model, no features discarded and colinear features should have equal weight\n",
    "    '''\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 71) #randomly shuffle before splitting\n",
    "    cv_lm_r2s = [] #collect the validation results\n",
    "    \n",
    "    #returns 5 index sets for cross vallidation\n",
    "    for train_ind, val_ind in kf.split(X_train,y_train):\n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "        ## This step fits the Standard Scaler to the training data\n",
    "        ## Essentially it finds the mean and standard deviation of each variable in the training set\n",
    "        #X_train = pd.DataFrame(X_train, columns = cols)\n",
    "        std = StandardScaler()\n",
    "        #std.fit(X_train.values)\n",
    "\n",
    "        #apply scalar to train and validation set\n",
    "        X_tr = std.fit_transform(X_train)\n",
    "        X_v = std.fit_transform(X_val)\n",
    "           \n",
    "        lr_model_ridge = Ridge(alpha = a)\n",
    "        lr_model_ridge.fit(X_tr, y_train)\n",
    "    \n",
    "    X_te = std.transform(X_test.values)\n",
    "    mae_value(X_te, y_test,  lr_model_ridge)\n",
    "    r2_value(X_te, y_test, lr_model_ridge)\n",
    "    print('Feature coefficient results: \\n')\n",
    "    for feature, coef in zip(X_train.columns, lr_model_ridge.coef_):\n",
    "        print(feature, ':', f'{coef:.2f}') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this helps with the way kf will generate indices below\n",
    "columns = pd.get_dummies(X_train).columns\n",
    "alpha = 10000\n",
    "X, y = np.array(X_train), np.array(y_train)\n",
    "ridge_model_cv(X, y, alpha, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
